{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d3e3e0",
   "metadata": {},
   "source": [
    "# 1.Import libraries and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "from math import sqrt\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788405fa",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc74cc",
   "metadata": {},
   "source": [
    "## 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(handel,old_handel):\n",
    "    dfe=pd.read_csv(handel,index_col=None)\n",
    "    df1=pd.read_csv(r\"data/peridic.csv\",index_col=None)\n",
    "    dfe= dfe.loc[:, ~dfe.columns.str.contains('^Unnamed')]\n",
    "    nul=[np.NaN]*len(dfe.Molecule)\n",
    "    for char in ['e1','e2']:\n",
    "        dfe[char]=nul\n",
    "    for char in df1.Symbol:\n",
    "        ind1=dfe.loc[dfe['Molecule'].str.contains(r'^'+char+r'\\D')].index.values\n",
    "        ind2=dfe.loc[dfe['Molecule'].str.contains(char+r'$')].index.values\n",
    "        ind3=dfe.loc[dfe['Molecule'].str.contains(r'^'+char+r'2')].index.values\n",
    "        #print(char)\n",
    "        #print(df1[df1.Symbol==char].Period.values)\n",
    "        dfe.loc[ind1,'e1']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind2,'e2']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind3,'e1']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind3,'e2']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "    g=dfe\n",
    "    g['n1']=g.A1-g.e1\n",
    "    g['n2']=g.A2-g.e2\n",
    "    g.loc[g.atom2=='H','p2']=[1]*len(g.loc[g.atom2=='H']['p2'])\n",
    "    g.loc[g.atom1=='H','p1']=[1]*len(g.loc[g.atom1=='H']['p1'])\n",
    "    g.loc[g.atom2=='H','g2_lan_act']=[1]*len(g.loc[g.atom2=='H']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='H','g1_lan_act']=[1]*len(g.loc[g.atom1=='H']['g1_lan_act'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    g.loc[g.atom2=='D','p2']=[1]*len(g.loc[g.atom2=='D']['p2'])\n",
    "    g.loc[g.atom1=='D','p1']=[1]*len(g.loc[g.atom1=='D']['p1'])\n",
    "    g.loc[g.atom2=='T','p2']=[1]*len(g.loc[g.atom2=='T']['p2'])\n",
    "    g.loc[g.atom1=='T','p1']=[1]*len(g.loc[g.atom1=='T']['p1'])\n",
    "    g.loc[g.atom2=='D','g2']=[1]*len(g.loc[g.atom2=='D']['g2'])\n",
    "    g.loc[g.atom1=='D','g1']=[1]*len(g.loc[g.atom1=='D']['g1'])\n",
    "    g.loc[g.atom2=='T','g2']=[1]*len(g.loc[g.atom2=='T']['g2'])\n",
    "    g.loc[g.atom1=='T','g1']=[1]*len(g.loc[g.atom1=='T']['g1'])\n",
    "    g.loc[g.atom2=='D','g2_lan_act']=[1]*len(g.loc[g.atom2=='D']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='D','g1_lan_act']=[1]*len(g.loc[g.atom1=='D']['g1_lan_act'])\n",
    "    g.loc[g.atom2=='T','g2_lan_act']=[1]*len(g.loc[g.atom2=='T']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='T','g1_lan_act']=[1]*len(g.loc[g.atom1=='T']['g1_lan_act'])\n",
    "    g.loc[g.atom2=='D','g2_lan_act_iso']=[0]*len(g.loc[g.atom2=='D']['g2_lan_act_iso'])\n",
    "    g.loc[g.atom1=='D','g1_lan_act_iso']=[0]*len(g.loc[g.atom1=='D']['g1_lan_act_iso'])\n",
    "    g.loc[g.atom2=='T','g2_lan_act_iso']=[-1]*len(g.loc[g.atom2=='T']['g2_lan_act_iso'])\n",
    "    g.loc[g.atom1=='T','g1_lan_act_iso']=[-1]*len(g.loc[g.atom1=='T']['g1_lan_act_iso'])\n",
    "    g.loc[g.atom2=='H','g2_lan_act_iso']=[1]*len(g.loc[g.atom2=='H']['g2_lan_act_iso'])\n",
    "    g.loc[g.atom1=='H','g1_lan_act_iso']=[1]*len(g.loc[g.atom1=='H']['g1_lan_act_iso'])\n",
    "    g['sum_p']=g['p1']+g['p2']\n",
    "    g['sum_g']=g.g1_lan_act+g.g2_lan_act\n",
    "    g['diff_p']=abs(g['p1']-g['p2'])\n",
    "    g['diff_g']=abs(g['g1_lan_act']-g['g2_lan_act'])\n",
    "    g['product_p']=g['p1']*g['p2']\n",
    "    g['product_g']=g['g1_lan_act']*g['g1_lan_act']\n",
    "    g['Reduced_g']=(g.g1_lan_act*g.g2_lan_act)/(g.g1_lan_act+g.g2_lan_act)\n",
    "    g['Reduced_p']=(g.p1*g.p2)/(g.p1+g.p2)\n",
    "    g['g_average']=(g.g1+g.g2)/2\n",
    "    g['g_average_lan_act']=(g.g1_lan_act+g.g2_lan_act)/2\n",
    "    g['g_average_lan_act_iso']=(g.g1_lan_act_iso+g.g2_lan_act_iso)/2\n",
    "    g['Re (\\AA)^-1']=1/((g['Re (\\AA)']))\n",
    "    g['Re (au)']=((g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['Re (au)^-1']=1/((g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['Re (au)^2']=((g['Re (\\AA)'])*1.8897259885789)**2\n",
    "    g['Re (au)^-2']=1/g['Re (au)^2']\n",
    "    g['4*(np.pi**2)*Re (au)']=(4*(np.pi**2)*(g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['4*(np.pi**2)*Re (au)^-1']=1/(4*(np.pi**2)*(g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['omega_e (au)^-2']=1/((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['4*(np.pi**2)*omega_e (au)^-2']=1/((2*(np.pi)*g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['omega_e (au)']=(g['omega_e (cm^{-1})']*(0.0000046))\n",
    "    g['omega_e (au)^2']=((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['4*(np.pi**2)*omega_e (au)^2']=4*(np.pi**2)*((g['omega_e (cm^{-1})']*(0.0000046))**2)\n",
    "    g['K']=(4*(np.pi**2)*((g['omega_e (cm^{-1})'])**2)*g['Reduced mass'])\n",
    "    g['sqrt(K)']=np.sqrt(4*(np.pi**2)*((g['omega_e (cm^{-1})'])**2)*g['Reduced mass'])\n",
    "    g['4*(np.pi**2)*omega_e (au)']=4*(np.pi**2)*((g['omega_e (cm^{-1})']*(0.0000046)))\n",
    "    g['4*(np.pi**2)*Re (au)*omega_e (au)^2']=g['4*(np.pi**2)*Re (au)']*((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['ve1']=g['g1_lan_act']\n",
    "    g['ve2']=g['g2_lan_act']\n",
    "    g['log(D_e)/(R_e^3*Z_1*Z_2)']=np.log((g[\"D0 (eV)\"]*0.037)/((g[\"Re (au)\"]**3)*g.e1*g.e2))\n",
    "    g.loc[g.g2_lan_act==18,'ve2']=[0]*len(g.loc[g.g2_lan_act==18]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==18,'ve1']=[0]*len(g.loc[g.g1_lan_act==18]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==17,'ve2']=[7]*len(g.loc[g.g2_lan_act==17]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==17,'ve1']=[7]*len(g.loc[g.g1_lan_act==17]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==16,'ve2']=[6]*len(g.loc[g.g2_lan_act==16]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==16,'ve1']=[6]*len(g.loc[g.g1_lan_act==16]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==15,'ve2']=[5]*len(g.loc[g.g2_lan_act==15]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==15,'ve1']=[5]*len(g.loc[g.g1_lan_act==15]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==14,'ve2']=[4]*len(g.loc[g.g2_lan_act==14]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==14,'ve1']=[4]*len(g.loc[g.g1_lan_act==14]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==13,'ve2']=[3]*len(g.loc[g.g2_lan_act==13]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==13,'ve1']=[3]*len(g.loc[g.g1_lan_act==13]['g1_lan_act'])\n",
    "    g.loc[g.type2=='Transition Metal','ve2']=[2]*len(g.loc[g.type2=='Transition Metal']['g2_lan_act'])\n",
    "    g.loc[g.type1=='Transition Metal','ve1']=[2]*len(g.loc[g.type1=='Transition Metal']['g1_lan_act'])\n",
    "    g= g.loc[:, ~g.columns.str.contains('^Unnamed')]\n",
    "    g_dict=g.to_dict(orient='list')\n",
    "    old=pd.read_csv(old_handel)\n",
    "    old=old[old[\"Te (cm^{-1})\"]==0]\n",
    "    old.drop_duplicates(inplace=True)\n",
    "    gr=g[g[\"Re (\\AA)\"].isna()==False]\n",
    "    gw=gr[gr[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    g_new=g.loc[g['Molecule'].isin(old.Molecule)==False]\n",
    "    g_old=g.loc[g['Molecule'].isin(old.Molecule)]\n",
    "    gr_old=g_old[g_old[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_old=gr_old[gr_old[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    gr_new=g_new[g_new[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_new=gr_new[gr_new[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    reverse=['A1','A2','g1','g2','p1','p2','g1iso','g2iso','g1_lan_act','g2_lan_act','g1_lan_act_iso','g2_lan_act_iso','atom1','atom2','type1','type2','e1','e2','ve1','ve2']\n",
    "    for key,value in g_dict.items():\n",
    "        if key in reverse:\n",
    "            continue \n",
    "        else:\n",
    "            g_dict[key]=value+value\n",
    "            #=g_dict[key].append(g_dict[key])\n",
    "    s=0        \n",
    "    for i in range(len(reverse)):\n",
    "            if s==len(reverse):\n",
    "                break\n",
    "            A=g_dict[reverse[s]]+g_dict[reverse[s+1]]\n",
    "            B=g_dict[reverse[s+1]]+g_dict[reverse[s]]\n",
    "            g_dict[reverse[s]]=A\n",
    "            g_dict[reverse[s+1]]=B\n",
    "            s=s+2\n",
    "    g_expand=pd.DataFrame.from_dict(g_dict, orient='columns')\n",
    "    g_expand.drop_duplicates(subset=['A1','A2','g1','g2','p1','p2','g1iso','g2iso','g1_lan_act','g2_lan_act','g1_lan_act_iso','g2_lan_act_iso','atom1','atom2','type1','type2','ve1','ve2'], keep='first', inplace=True, ignore_index=False)\n",
    "    gr_expand=g_expand[g_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_expand=gr_expand[gr_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "\n",
    "    g_new_expand=g_expand.loc[g_expand['Molecule'].isin(old.Molecule)==False]\n",
    "    g_old_expand=g_expand.loc[g_expand['Molecule'].isin(old.Molecule)]\n",
    "    gr_old_expand=g_old_expand[g_old_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_old_expand=gr_old_expand[gr_old_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    gr_new_expand=g_new_expand[g_new_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_new_expand=gr_new_expand[gr_new_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    return g,gr,gw, g_old, g_new, gr_old, gw_old, gr_new, gw_new, g_expand, gr_expand, gw_expand, g_old_expand, g_new_expand, gr_old_expand, gw_old_expand, gr_new_expand, gw_new_expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e7c66",
   "metadata": {},
   "source": [
    "## 3.2 Function that perfroms the MC splits and train fit the LR and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model(data,strata,test_size,features,logtarget,target,n_splits=1000):\n",
    "    r_y_train_preds={}\n",
    "    r_y_test_preds={}\n",
    "    trval={} #intiate a dictionary to store optmized kernels and scores\n",
    "    start_time = time.time()\n",
    "    RMSE=[]\n",
    "    RMSLE=[]\n",
    "    MAE=[]\n",
    "    R=[]\n",
    "    Train_RMSE=[]\n",
    "    Train_RMSLE=[]\n",
    "    Train_MAE=[]\n",
    "    Train_R=[]\n",
    "    train=[]\n",
    "    test=[]\n",
    "    mcs = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size,random_state=42)\n",
    "    #skf = StratifiedKFold(n_splits=0, shuffle=True, random_state=42)\n",
    "    loo = LeaveOneOut()\n",
    "    #print(loo.get_n_splits(data))\n",
    "    s=0\n",
    "\n",
    "    #for train_index, test_index in loo.split(data):\n",
    "    for train_index, test_index in mcs.split(data,strata):\n",
    "        #print(train_index)\n",
    "        re_train_set1 = data.iloc[train_index]\n",
    "        re_train_set1['ind']=train_index\n",
    "        re_test_set1 = data.iloc[test_index]\n",
    "        re_test_set1['ind']=test_index\n",
    "        print('size of training set before removing mirror molecules',len(re_train_set1))\n",
    "        \n",
    "        re_train_set=re_train_set1[~re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())]\n",
    "        re_test_set=pd.concat([re_test_set1,re_train_set1[re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())]])\n",
    "        \n",
    "        for i in re_train_set['Molecule'].isin([re_test_set['Molecule']]):\n",
    "            if i ==True:\n",
    "                print(i)\n",
    "        print('size of training set after removing mirror molecules',len(re_train_set))\n",
    "        #print('size of test set after adding mirror molecules',len(re_test_set))\n",
    "        train.append(re_train_set['Molecule'])\n",
    "        if (re_test_set['Molecule'].tolist()) in test:\n",
    "            #continue\n",
    "            break\n",
    "\n",
    "        test.append(re_test_set['Molecule'].tolist())\n",
    "        #print(test)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        trval[str(s)]={}\n",
    "        trval[str(s)]['$\\sigma^2$']=1\n",
    "        trval[str(s)]['length scale']=1\n",
    "        trval[str(s)]['noise level']=1\n",
    "      \n",
    "        \n",
    "        \n",
    "        reg = LinearRegression().fit(re_train_set[features], re_train_set[logtarget])\n",
    "        \n",
    "        r_y_train_pred_log=reg.predict(re_train_set[features])\n",
    "        \n",
    "        r_y_test_pred_log=reg.predict(re_test_set[features])\n",
    "        \n",
    "        \n",
    "        \n",
    "        r_y_train_pred=np.exp(r_y_train_pred_log)\n",
    "        r_y_test_pred=np.exp(r_y_test_pred_log)\n",
    "        \n",
    "        \n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('yalaaahwy')\n",
    "        r_y_test_pred=(np.array(r_y_test_pred))\n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('y5rabaaaay')\n",
    "                \n",
    "                \n",
    "        #if (100*(np.sqrt(mean_squared_error(re_test_set['Re (\\AA)'],r_y_test_pred)))/((data['Re (\\AA)']).max()-(data['Re (\\AA)']).min())) > 3.0:\n",
    "         #   print(re_test_set['Molecule'].isin(test))\n",
    "          #  continue\n",
    "        \n",
    "        \n",
    "        for  mol in  re_test_set['Molecule'].tolist():\n",
    "            test.append(mol)\n",
    "\n",
    "\n",
    "        RMSE.append(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred)))\n",
    "\n",
    "        trval[str(s)]['RMSE']=RMSE[-1]\n",
    "        \n",
    "        Train_RMSE.append(np.sqrt(mean_squared_error(re_train_set[target],r_y_train_pred)))\n",
    "\n",
    "        trval[str(s)]['Train_RMSE']=Train_RMSE[-1]\n",
    "        \n",
    "        RMSLE.append(np.sqrt(mean_squared_error(re_test_set[logtarget],r_y_test_pred_log)))\n",
    "\n",
    "        trval[str(s)]['RMSLE']=RMSLE[-1]\n",
    "        \n",
    "                \n",
    "        Train_RMSLE.append(np.sqrt(mean_squared_error(re_train_set[logtarget],r_y_train_pred_log)))\n",
    "\n",
    "        trval[str(s)]['Train_RMSLE']=Train_RMSLE[-1]\n",
    "\n",
    "        MAE.append(sum(abs(re_test_set[target]-(r_y_test_pred)))/len(re_test_set[target]))\n",
    "\n",
    "        trval[str(s)]['MAE']=MAE[-1]\n",
    "        \n",
    "        Train_MAE.append(sum(abs(re_train_set[target]-(r_y_train_pred)))/len(re_train_set[target]))\n",
    "\n",
    "        trval[str(s)]['Train_MAE']=Train_MAE[-1]\n",
    "\n",
    "        R.append(100*(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred)))/((data[target]).max()-(data[target]).min()))\n",
    "\n",
    "        trval[str(s)]['R']=R[-1]\n",
    "        \n",
    "        #if trval[str(s)]['R'] > 3.0:\n",
    "         #   continue\n",
    "            #print(re_test_set['Molecule'])\n",
    "\n",
    "        #print(\"Molecule\",re_test_set[\"Molecule\"],'-------')\n",
    "        #print('sigma: ',trval[str(s)]['$\\sigma^2$'],\"length scale: \",trval[str(s)]['length scale'],'noise level: ',trval[str(s)]['noise level'])\n",
    "        \n",
    "        print(\"Split:\",s)\n",
    "        print('Molecule',re_test_set['Molecule'].tolist()[-1])\n",
    "       # print('Train MAE', np.array(Train_MAE).mean(),trval[str(s)]['Train_MAE'])\n",
    "        print('Test MAE', np.array(MAE).mean(),trval[str(s)]['MAE'])\n",
    "        print('Test R%: ',np.array(R).mean(),trval[str(s)]['R'])\n",
    "        print('Train RMSE: ',np.array(Train_RMSE).mean(),trval[str(s)]['Train_RMSE'])\n",
    "        print('Test RMSE: ',np.array(RMSE).mean(),trval[str(s)]['RMSE'])\n",
    "      #  print('Train RMSLE: ',np.array(Train_RMSLE).mean(),trval[str(s)]['Train_RMSLE'])\n",
    "     #   print('Test RMSLE: ',np.array(RMSLE).mean(),trval[str(s)]['RMSLE'])\n",
    "              \n",
    "        \n",
    "    \n",
    "        s=s+1\n",
    "        \n",
    "\n",
    "        for i in range(len(re_train_set.ind)):\n",
    "            if re_train_set.ind.tolist()[i] not in r_y_train_preds:   \n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]]=[r_y_train_pred[i]]\n",
    "\n",
    "                #print(\"Molecule: \",re_train_set.loc[train_index[i],'Molecule'],\"true: \",gr.loc[train_index[i],'Re (\\AA)'],\"pred: \",r_y_train_pred[i],\"standard deviation: \",r_std_train[i])\n",
    "\n",
    "            else:\n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]].append(r_y_train_pred[i])\n",
    "                \n",
    "        for i in range(len(re_test_set.ind)):\n",
    "            if re_test_set.ind.tolist()[i] not in r_y_test_preds:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]]=[r_y_test_pred[i]]\n",
    "            else:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]].append(r_y_test_pred[i])\n",
    "    end_time = time.time()\n",
    "    retime=end_time-start_time\n",
    "    retime\n",
    "    return trval,train,test,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_y_test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534641d6",
   "metadata": {},
   "source": [
    "## 3.4 Ploting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0032567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df,x,y,target,r_y_train_preds,r_y_test_preds):\n",
    "    re_train_preds=[]\n",
    "    re_test_preds=[]\n",
    "    out=[]\n",
    "    for index in range(len(df.index)):\n",
    "            re_train_preds.append(np.array(r_y_train_preds[index]).mean())\n",
    "            re_test_preds.append((np.array(r_y_test_preds[index])).mean())\n",
    "    fig, ax =pyplot.subplots(figsize=(7,7))\n",
    "    pyplot.xticks(fontsize=16)\n",
    "    pyplot.yticks(fontsize=16)\n",
    "    #ax.set_xlim(0, df[target].max())\n",
    "    ax.errorbar(df[target], re_train_preds, fmt ='o',label='Training set')\n",
    "    ax.errorbar(df[target], re_test_preds, fmt ='o',label='Validation set')\n",
    "\n",
    "    line=df[target].tolist()\n",
    "    line.append(0)\n",
    "    line.append(np.ceil(np.array(re_test_preds).max()))\n",
    "    ax.plot(line,line,'--k')\n",
    "    #pyplot.xticks(ticks=np.linspace(1, 4, num=4))\n",
    "    #pyplot.yticks(ticks=np.linspace(1, 4, num=4))\n",
    "    #ax.plot([0, 1], [0, 1], transform=ax.transAxes)\n",
    "    pyplot.xlim(np.array(line).min(),np.ceil(np.array(line).max()))\n",
    "    pyplot.ylim(np.array(line).min(),np.ceil(np.array(line).max()))\n",
    "    ax.legend(prop={'size': 18})\n",
    "    pyplot.xlabel(x,fontdict={'size': 16})\n",
    "    pyplot.ylabel(y,fontdict={'size': 16})\n",
    "    return re_train_preds,re_test_preds,out,fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b45f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(data_describtion,df,target,re_test_preds,no_molecules,MAE,RMSE,R,handle):\n",
    "    results={}\n",
    "    results[data_describtion]={}\n",
    "    results[data_describtion]['Number of molecules in the whole data set']=no_molecules\n",
    "    results[data_describtion]['MAE']=str(np.array(MAE).mean())\n",
    "    results[data_describtion]['RMSE']=str(np.array(RMSE).mean())\n",
    "    results[data_describtion]['$r%$']=str((np.array(R).mean()))\n",
    "    results=pd.DataFrame.from_dict(results) \n",
    "    results.to_csv(handle, index=True)  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95932d5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10832593",
   "metadata": {},
   "source": [
    "# 3. Body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2bfe0",
   "metadata": {},
   "source": [
    "## 3.1 Loading and organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ffd29",
   "metadata": {},
   "outputs": [],
   "source": [
   "g,gr,gw, g_old, g_new, gr_old, gw_old, gr_new, gw_new, g_expand, gr_expand, gw_expand, g_old_expand, g_new_expand, gr_old_expand, gw_old_expand, gr_new_expand, gw_new_expand=load(handel=r\"data/g.csv\",old_handel=r\"data/list of molecules used in Xiangue and Jesus paper.csv\")"
  },
  {
   "cell_type": "markdown",
   "id": "ad16452d",
   "metadata": {},
   "source": [
    "### 3.1.1 Stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba2d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gw_expand=gw\n",
    "gw_expand=gw_expand[~gw_expand['Molecule'].isin(['XeCl','AgBi','Hg2','HgCl'])]\n",
    "gw_expand['wcat']=gw_expand['Re (\\AA)']\n",
    "#gw_expand=gw_expand.drop_duplicates(subset=['p1','p2','g1_lan_act','g2_lan_act'],ignore_index=True)\n",
    "#np.sqrt(gw_expand['Reduced mass']**2+gw_expand['p1']**2+gw_expand['p2']**2+gw_expand['g1_lan_act']**2+gw_expand['g2_lan_act']**2)\n",
    "gw_expand_unique=np.unique(gw_expand['wcat'])\n",
    "ind=[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,302]\n",
    "print(len(gw_expand_unique))\n",
    "for i in range(len(ind)-1):\n",
    "    gw_expand['wcat'].where((gw_expand['wcat']>gw_expand_unique[ind[i+1]])|(gw_expand['wcat']<=gw_expand_unique[ind[i]]),gw_expand_unique[ind[i]],inplace=True)\n",
    "np.unique(gw_expand['wcat'],return_counts=True)\n",
    "#len(np.unique(gw_expand['wcat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4562036",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_expand['ln(e1*e2)']=np.log(gw_expand['e1']*gw_expand['e2'])\n",
    "gw_expand['mu^(1/2)']=(np.sqrt(gw_expand['Reduced mass']))\n",
    "gw_expand['ln(mu^(1/2))']=np.log(np.sqrt(gw_expand['Reduced mass']))\n",
    "gw_expand['ln(w)']=np.log(gw_expand['omega_e (cm^{-1})'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trval,train,test,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_y_test_preds=ml_model(data=gw_expand,strata=gw_expand['wcat'],test_size=31,features=['sum_p','sum_g','ln(e1*e2)','ln(mu^(1/2))','Re (\\AA)'],target='omega_e (cm^{-1})',logtarget='ln(w)',n_splits=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da16257",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train_preds,re_test_preds,out,fig,ax=plot_results(gw_expand,'True $\\omega_e (cm^{-1})$','Predicted $\\omega_e (cm^{-1})$','omega_e (cm^{-1})',r_y_train_preds,r_y_test_preds);\n",
    "pyplot.savefig('w_lr_1.svg')\n",
    "for i in range(len(re_test_preds)):\n",
    "    if abs(gw_expand['omega_e (cm^{-1})'].tolist()[i]-re_test_preds[i])<300:\n",
    "        continue\n",
    "    ax.annotate(gw_expand['Molecule'].tolist()[i], (gw_expand['omega_e (cm^{-1})'].tolist()[i], re_test_preds[i]))\n",
    "pyplot.savefig('w_lr_1_annot.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results('$\\omega_e (cm^{-1})$ LR results with features $p_1+p_2$, $g_1+g_2$, $ln(Z_1 \\times Z_2)$, $R_e (A)$',gw_expand,'omega_e (cm^{-1})',re_test_preds,310,MAE,RMSE,R,r\"stat_summ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e66bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stat = pd.DataFrame(list(zip(Train_MAE,Train_RMSE,Train_R,MAE,RMSE,R)),columns =['Train_MAE','Train_RMSE','Train_R','MAE','RMSE','R'])\n",
    "split_stat.to_csv('split_stat.csv')\n",
    "gw_expand['re_test_preds']=re_test_preds\n",
    "gw_expand['re_train_preds']=re_test_preds\n",
    "#re_train_preds,re_train_std\n",
    "gw_expand.to_csv('gw_expand_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e10574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
