{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429e83a1",
   "metadata": {},
   "source": [
    "# Model r1\n",
    "\n",
    "Model r1 is the same as in Liu et al.[[1]](#1). A GPR model with a Matern 1/2 kernel and with groups and periods of the constituent atoms as features. We explicitly express the model's prior mean functions as linear functions in the groups and periods of the diatomic molecules' constituent atoms.\n",
    "\n",
    "$m_{r1-r2} = \\beta_0^{r1-r2}+\\beta_{1}^{r1-r2}(p_1+p_2) + \\beta_{2}^{r1-r2}(g_1+g_2)$\n",
    "\n",
    "where  $\\beta_k^{r1-r2}$, $k \\in \\{0,1,2\\}$ are the linear coefficients of  $m_{r1-r2}$.\n",
    "\n",
    "## References\n",
    "<a id=\"1\">[1]</a> \n",
    "X. Liu, S. Truppe, G. Meijer and J. Pérez-Ríos, Journal of\n",
    "Cheminformatics, 2020, 12, 31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962a852",
   "metadata": {},
   "source": [
    "## 1.Import libraries and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "import math\n",
    "from math import sqrt\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669aa54",
   "metadata": {},
   "source": [
    "# 2. Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572560e",
   "metadata": {},
   "source": [
    "## Increasing the maximum number of iterations for the optmizer of the Gaussianprocesses object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPR(GaussianProcessRegressor): #MyGPR(GaussianProcessRegressor) class specify the maximum number of iterations, tolerance, and optimizer explicitly in the sklearn.gaussian_process GaussianProcessRegressor object \n",
    "    def __init__(self, *args, max_iter=1000000, gtol=1e-6, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._max_iter = max_iter #maximum number of iterations\n",
    "        self._gtol = gtol #tolerance\n",
    "\n",
    "    def _constrained_optimization(self, obj_func, initial_theta, bounds): \n",
    "        if self.optimizer == \"fmin_l_bfgs_b\": #optmizer \n",
    "            opt_res = scipy.optimize.minimize(obj_func, initial_theta, method=\"L-BFGS-B\", jac=True, bounds=bounds,tol=self._gtol, options={'maxiter':self._max_iter, 'disp':True})\n",
    "            theta_opt, func_min = opt_res.x, opt_res.fun\n",
    "        elif callable(self.optimizer):\n",
    "            theta_opt, func_min = self.optimizer(obj_func, initial_theta, bounds=bounds)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown optimizer %s.\" % self.optimizer)\n",
    "            \n",
    "        return theta_opt, func_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9389d4",
   "metadata": {},
   "source": [
    "# 3. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e04da",
   "metadata": {},
   "source": [
    "## 3.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5444f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(handel,per_tab=r\"peridic.csv\"): #Load is a function that takes the handles of the two CSV files containing the full data set (including old and new data) and the data set containing the data from Liu et al. 2021 and returns multiple pandas data frames of the data as defined below\n",
    "    dfe=pd.read_csv(handel,index_col=None)\n",
    "    df1=pd.read_csv(per_tab,index_col=None) #Includes information from the periodic table for each element\n",
    "    dfe= dfe.loc[:, ~dfe.columns.str.contains('^Unnamed')]\n",
    "    g=dfe\n",
    "    g.loc[g.atom2=='H','p2']=[1]*len(g.loc[g.atom2=='H']['p2'])\n",
    "    g.loc[g.atom1=='H','p1']=[1]*len(g.loc[g.atom1=='H']['p1'])\n",
    "    g.loc[g.atom2=='H','g2_lan_act']=[1]*len(g.loc[g.atom2=='H']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='H','g1_lan_act']=[1]*len(g.loc[g.atom1=='H']['g1_lan_act'])\n",
    "    #the 'lan_act' extension to 'g1' and 'g2' indicates that Lanthanides and Actinides are included and both are indicated by group number 3.\n",
    "    \n",
    "    #Defining the groups and periods of the Hydrogen isotopologues\n",
    "    g.loc[g.atom2=='D','p2']=[1]*len(g.loc[g.atom2=='D']['p2'])\n",
    "    g.loc[g.atom1=='D','p1']=[1]*len(g.loc[g.atom1=='D']['p1'])\n",
    "    g.loc[g.atom2=='T','p2']=[1]*len(g.loc[g.atom2=='T']['p2'])\n",
    "    g.loc[g.atom1=='T','p1']=[1]*len(g.loc[g.atom1=='T']['p1'])\n",
    "    g.loc[g.atom2=='D','g2']=[1]*len(g.loc[g.atom2=='D']['g2'])\n",
    "    g.loc[g.atom1=='D','g1']=[1]*len(g.loc[g.atom1=='D']['g1'])\n",
    "    g.loc[g.atom2=='T','g2']=[1]*len(g.loc[g.atom2=='T']['g2'])\n",
    "    g.loc[g.atom1=='T','g1']=[1]*len(g.loc[g.atom1=='T']['g1'])\n",
    "    g.loc[g.atom2=='D','g2_lan_act']=[1]*len(g.loc[g.atom2=='D']['g2_lan_act'])  \n",
    "    g.loc[g.atom1=='D','g1_lan_act']=[1]*len(g.loc[g.atom1=='D']['g1_lan_act'])\n",
    "    g.loc[g.atom2=='T','g2_lan_act']=[1]*len(g.loc[g.atom2=='T']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='T','g1_lan_act']=[1]*len(g.loc[g.atom1=='T']['g1_lan_act']) \n",
    "    g= g.loc[:, ~g.columns.str.contains('^Unnamed')]\n",
    "    g_dict=g.to_dict(orient='list')\n",
    "    #creating different pandas dataframes for different purposes\n",
    "    gr=g[g[\"Re (\\AA)\"].isna()==False] #gr only contains molecules that have R_e available \n",
    "    # permuting the properties of atoms 1 and 2 in the diatomic molecules as described in Liu et al., 2021 and in the manuscript, to create expanded data frames containing both A-B and B-A molecules\n",
    "    reverse=['A1','A2','g1','g2','p1','p2','g1_lan_act','g2_lan_act','atom1','atom2','type1','type2']\n",
    "    for key,value in g_dict.items():\n",
    "        if key in reverse:\n",
    "            continue \n",
    "        else:\n",
    "            g_dict[key]=value+value\n",
    "    s=0        \n",
    "    for i in range(len(reverse)):\n",
    "            if s==len(reverse):\n",
    "                break\n",
    "            A=g_dict[reverse[s]]+g_dict[reverse[s+1]]\n",
    "            B=g_dict[reverse[s+1]]+g_dict[reverse[s]]\n",
    "            g_dict[reverse[s]]=A\n",
    "            g_dict[reverse[s+1]]=B\n",
    "            s=s+2\n",
    "    #the extension '-expand' indicates the inclusion of both A-B and B-A variations of the diatomic molecule in the dataframe \n",
    "    g_expand=pd.DataFrame.from_dict(g_dict, orient='columns')\n",
    "    g_expand.drop_duplicates(subset=['A1','A2','g1','g2','p1','p2','g1_lan_act','g2_lan_act','atom1','atom2','type1','type2'], keep='first', inplace=True, ignore_index=False)\n",
    "    gr_expand=g_expand[g_expand[\"Re (\\AA)\"].isna()==False]\n",
    "\n",
    "    return gr,gr_expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25758b2f",
   "metadata": {},
   "source": [
    "## 3.3 Function that perfroms the MC-CV splits, train the GPR and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model(data,strata,test_size,features,prior_features,logtarget,target,nu,normalize_y,n_splits=1000): #function used for implementing the MC-CV GPR model\n",
    "    r_y_train_preds={} # Initiate a dictionary to store training predictions\n",
    "    r_y_test_preds={} # Initiate a dictionary to store testing predictions\n",
    "    r_train_stds={} # Initiate a dictionary to store training standard deviations\n",
    "    r_test_stds={} # Initiate a dictionary to store testing standard deviations\n",
    "    trval={} #intiate a dictionary to store optimized kernels and scores\n",
    "    start_time = time.time() #Timing the algorithm\n",
    "    RMSE=[] # Intiate a list to store the test RMSE of all MC-CV steps\n",
    "    RMSLE=[] # Intiate a list to store the test RMSLE of all MC-CV steps\n",
    "    MAE=[] # Intiate a list to store the test MAE of all MC-CV steps\n",
    "    R=[] # Intiate a list to store the test normalized RMSE % of all MC-CV steps\n",
    "    Train_RMSE=[] # Intiate a list to store the train RMSE of all MC-CV steps\n",
    "    Train_RMSLE=[] # Intiate a list to store the train RMSLE of all MC-CV steps\n",
    "    Train_MAE=[] # Intiate a list to store the train MAE of all MC-CV steps\n",
    "    Train_R=[] # Intiate a list to store the train normalized RMSE % of all MC-CV steps\n",
    "    mean_std=[] # Intiate a list to store the mean test std of all MC-CV steps\n",
    "    train=[] # Intiate a list of lists to store molecules used for training in each split \n",
    "    test=[] # Intiate a list of lists to store molecules used for testing in each split\n",
    "    mcs = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size,random_state=42) # Using stratified shuffle split object from sklearn for the MC-CV scheme \n",
    "    s=0\n",
    "\n",
    "    for train_index, test_index in mcs.split(data,strata):\n",
    "        # The naming 'testing' is used insted of 'validatining' since in each MC-CV step the validation set is used to siulate the testing stage\n",
    "        re_train_set1 = data.iloc[train_index] # The dataframe's training rows returend from mcs.split(data,strata)\n",
    "        re_train_set1['ind']=train_index #The dataframe's training rows' indicies returend from mcs.split(data,strata)\n",
    "        re_test_set1 = data.iloc[test_index] # The dataframe's testing rows returend from mcs.split(data,strata)\n",
    "        re_test_set1['ind']=test_index #The dataframe's testing rows' indicies returend from mcs.split(data,strata)\n",
    "        \n",
    "        re_train_set=re_train_set1[~re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())] #Removing A-B molecules from the training set if their mirror molecules (B-A molecules) are in the testing set\n",
    "        re_test_set=pd.concat([re_test_set1,re_train_set1[re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())]]) #Placing miror molecules from the training set in the testing set so that A-B and B-A moleculesa re both in the testing set\n",
    "        \n",
    "        for i in re_train_set['Molecule'].isin([re_test_set['Molecule']]):\n",
    "            if i ==True:\n",
    "                print('Warning: A molecule in the test set is aslo in the training set')\n",
    "        train.append(re_train_set['Molecule'])\n",
    "        if (re_test_set['Molecule'].tolist()) in test:\n",
    "            break \n",
    "\n",
    "        test.append(re_test_set['Molecule'].tolist())\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        trval[str(s)]={} # intiate a dictionary that stores the three parameters values after optimization for each split s\n",
    "        \n",
    "        \n",
    "        reg = LinearRegression().fit(re_train_set[prior_features], re_train_set[logtarget]) #Liner regression model to fix the constatns coefficients of the prirori mean function in each MC-CV step\n",
    "        \n",
    "        re_train_set['prior_mean']=reg.predict(re_train_set[prior_features])\n",
    "        re_test_set['prior_mean']=reg.predict(re_test_set[prior_features])\n",
    "        \n",
    "        \n",
    "        prior_mean='prior_mean'\n",
    "        signal_variance=(re_train_set[logtarget].var()) #Intiate constant cooefcient of the Matern kernel function \n",
    "        length_scale=(re_train_set[features].std()).mean() #Intiate length scale of the Matern kernel function \n",
    "        gpr = MyGPR(kernel=ConstantKernel(constant_value=signal_variance)*Matern(length_scale=length_scale, nu=nu)+WhiteKernel(noise_level=re_train_set[target].std()/np.sqrt(2),noise_level_bounds=(10**-15,1)),n_restarts_optimizer=20,normalize_y=normalize_y,random_state=42) #Using MYGPR class with the matern Kernel with multiplicative constant and additive white noise kernel as defined in the manuscript\n",
    "        gpr.fit(re_train_set[features], re_train_set[logtarget]-re_train_set[prior_mean]) # Optmizing the kernel parameters using the fitting data (the target is offset by the prior mean)\n",
    "\n",
    "\n",
    "        r_y_train_pred_log,r_std_train=gpr.predict(re_train_set[features], return_std=True) #train predictions, and train standard deviations \n",
    "        r_y_test_pred_log,r_std_test=gpr.predict(re_test_set[features], return_std=True) #test predictions, and train standard deviations \n",
    "        \n",
    "        r_y_train_pred_log=r_y_train_pred_log+np.array(re_train_set[prior_mean]) #adding the prior mean back \n",
    "        r_y_test_pred_log=r_y_test_pred_log+np.array(re_test_set[prior_mean]) #adding the prior mean back\n",
    "        \n",
    "        r_y_train_pred=r_y_train_pred_log #log transformation was not used in predicting R_e\n",
    "        r_y_test_pred=r_y_test_pred_log #log transformation was not used in predicting R_e\n",
    "\n",
    "        \n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('negative result') #indicates negative results if any \n",
    "        r_y_test_pred=(np.array(r_y_test_pred))\n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('negative result') #indicates negative results if any \n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "        for  mol in  re_test_set['Molecule'].tolist():\n",
    "            test.append(mol)\n",
    "        mean_std.append(np.array(r_std_test).mean()) #calculating mean of the standard deviations returned from gpr predictions\n",
    "\n",
    "        trval[str(s)]['mean_std']=mean_std[-1] #mean of the standard deviations returned from gpr predictions of split s\n",
    "\n",
    "        RMSE.append(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred))) #calculating test RMSE of the split and appending it to the test RMSE list \n",
    "\n",
    "        trval[str(s)]['RMSE']=RMSE[-1] #RMSE of split s\n",
    "        \n",
    "        Train_RMSE.append(np.sqrt(mean_squared_error(re_train_set[target],r_y_train_pred))) #calculating train RMSE of the split and appending it to the Train_RMSE list\n",
    "\n",
    "        trval[str(s)]['Train_RMSE']=Train_RMSE[-1] #Train RMSE of split s\n",
    "        \n",
    "        RMSLE.append(np.sqrt(mean_squared_error(re_test_set[logtarget],r_y_test_pred_log))) #calculating test RMSLE of the split and appending it to the test RMSLE list \n",
    "\n",
    "        trval[str(s)]['RMSLE']=RMSLE[-1] #Test RMSLE of split s\n",
    "        \n",
    "                \n",
    "        Train_RMSLE.append(np.sqrt(mean_squared_error(re_train_set[logtarget],r_y_train_pred_log))) #calculating train RMSLE of the split and appending it to the Train_RMSLE list \n",
    "\n",
    "        trval[str(s)]['Train_RMSLE']=Train_RMSLE[-1] #Train RMSE of split s\n",
    "\n",
    "        MAE.append(sum(abs(re_test_set[target]-(r_y_test_pred)))/len(re_test_set[target])) #calculating test MAE of the split and appending it to the test MAE list \n",
    "\n",
    "        trval[str(s)]['MAE']=MAE[-1] #Test MAE of split s\n",
    "        \n",
    "        Train_MAE.append(sum(abs(re_train_set[target]-(r_y_train_pred)))/len(re_train_set[target])) #calculating train MAE of the split and appending it to the Train_MAE list \n",
    "\n",
    "        trval[str(s)]['Train_MAE']=Train_MAE[-1] #Train MAE of split s\n",
    "\n",
    "        R.append(100*(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred)))/((data[target]).max()-(data[target]).min())) #calculating test R of the split and appending it to the test R list \n",
    "\n",
    "        trval[str(s)]['R']=R[-1] #Test R of split s\n",
    "\n",
    "    \n",
    "        s=s+1 # incrementing the MC-CV split counter\n",
    "        \n",
    "\n",
    "        for i in range(len(re_train_set.ind)):\n",
    "            if re_train_set.ind.tolist()[i] not in r_y_train_preds:   \n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]]=[r_y_train_pred[i]] #adding MC-CV train prediction list of a molecule of index 'i' which is not yet in re_train_set dictionary\n",
    "                r_train_stds[re_train_set.ind.tolist()[i]]=[r_std_train[i]] #adding MC-CV train GPR standard deviation list of a molecule of index 'i' not yet in r_train_stds dictionary\n",
    "            else:\n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]].append(r_y_train_pred[i]) #apeending new MC-CV train prediction to an existing list of predictions of a molecule indexed i in the r_y_train_preds dictionary\n",
    "                r_train_stds[re_train_set.ind.tolist()[i]].append(r_std_train[i]) #apeending new MC-CV train standard deviation to an existing list of predictions of a molecule indexed i in the r_train_stds dictionary\n",
    "                \n",
    "        for i in range(len(re_test_set.ind)):\n",
    "            if re_test_set.ind.tolist()[i] not in r_y_test_preds:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]]=[r_y_test_pred[i]] #adding MC-CV test prediction list of a molecule of index 'i' which is not yet in re_test_set dictionary\n",
    "                r_test_stds[re_test_set.ind.tolist()[i]]=[r_std_test[i]] #adding MC-CV test GPR standard deviation list of a molecule of index 'i' not yet in r_test_stds dictionary\n",
    "            else:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]].append(r_y_test_pred[i]) #apeending new MC-CV test prediction to an existing list of predictions of a molecule indexed 'i' in the r_y_test_preds dictionary\n",
    "                r_test_stds[re_test_set.ind.tolist()[i]].append(r_std_test[i]) #apeending new MC-CV test standard deviation to an existing list of predictions of a molecule indexed 'i' in the r_test_stds dictionary\n",
    "    end_time = time.time()\n",
    "    retime=end_time-start_time\n",
    "    retime # timing the validation stage\n",
    "    return trval,train,test,mean_std,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfc5b0",
   "metadata": {},
   "source": [
    "## 3.4 Ploting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df,x,y,target,r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds): #funtion to create scatter plots of training and testing predictions\n",
    "    re_train_preds=[] # initiating a list to store the average training predictions for each molecule over the MC-CV splits \n",
    "    re_train_std=[] # initiating a list to store the average training standard deviations for each molecule over the MC-CV splits\n",
    "    re_test_preds=[]  # initiating a list to store the average testing predictions for each molecule over the MC-CV splits \n",
    "    re_test_std=[] # initiating a list to store the average testing standard deviations for each molecule over the MC-CV splits\n",
    "    out=[] # intiating a list that stores the indices of the molecules that has never been used in testing (validation) set \n",
    "    for index in range(len(df.index)):\n",
    "            re_train_preds.append(np.array(r_y_train_preds[index]).mean()) \n",
    "            re_train_std.append(np.std(np.array(r_y_train_preds[index]))+np.array(r_train_stds[index]).mean())\n",
    "            re_test_preds.append((np.array(r_y_test_preds[index])).mean())\n",
    "            re_test_std.append(np.std(np.array(r_y_test_preds[index]))+np.array(r_test_stds[index]).mean())\n",
    "    fig, ax =pyplot.subplots(figsize=(7,7))\n",
    "    pyplot.xticks(fontsize=16)\n",
    "    pyplot.yticks(fontsize=16)\n",
    "    ax.errorbar(df[target], re_train_preds, yerr=re_train_std, fmt ='o',label='Training set')\n",
    "    ax.errorbar(df[target], re_test_preds, yerr=re_test_std, fmt ='o',label='Validation set')\n",
    "\n",
    "    line=df[target].tolist()\n",
    "    line.append(0)\n",
    "    line.append(np.ceil(np.array(re_test_preds).max()))\n",
    "    ax.plot(line,line,'--k')\n",
    "    pyplot.xticks(ticks=np.linspace(1, 4, num=4))\n",
    "    pyplot.yticks(ticks=np.linspace(1, 4, num=4))\n",
    "    pyplot.xlim(np.array(line).min(),np.ceil(np.array(line).max()))\n",
    "    pyplot.ylim(np.array(line).min(),np.ceil(np.array(line).max()))\n",
    "    ax.legend(prop={'size': 12})\n",
    "    pyplot.xlabel(x,fontdict={'size': 16})\n",
    "    pyplot.ylabel(y,fontdict={'size': 16})\n",
    "    return re_train_preds,re_train_std,re_test_preds,re_test_std,out,fig,ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38feeb",
   "metadata": {},
   "source": [
    "## 3.5 A function to repors a statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d69fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(data_describtion,df,target,re_test_preds,no_molecules,MAE,RMSE,R,handle): # A function that returns a data frame of the final results and scores of the model \n",
    "    results={}\n",
    "    results[data_describtion]={}\n",
    "    results[data_describtion]['Number of molecules in the whole data set']=no_molecules\n",
    "    results[data_describtion]['MAE']=str(np.array(MAE).mean())+' (+/-) '+str(round(abs(np.mean(abs(np.mean(np.array(df[target]))-(np.mean(re_test_preds)+np.std(re_test_preds))))-(np.mean(abs(np.mean(np.array(df[target]))-(np.mean(re_test_preds)-np.std(re_test_preds))))))/2,4))\n",
    "    results[data_describtion]['RMSE']=str(np.array(RMSE).mean())+' (+/-) '+str((abs(np.sqrt(np.mean(np.mean(np.array(df[target]))-(np.mean(re_test_preds)+np.std(re_test_preds)))**2)-(np.sqrt(np.mean((df[target].mean()-(np.mean(re_test_preds)-np.std(re_test_preds))))**2))).round(decimals=4))/2)\n",
    "    results[data_describtion]['$r%$']=str((np.array(R).mean()))+' (+/-) '+str(round((((abs(np.sqrt(np.mean(np.mean(np.array(df[target]))-(np.mean(re_test_preds)+np.std(re_test_preds)))**2)-(np.sqrt(np.mean((df[target].mean()-(np.mean(re_test_preds)-np.std(re_test_preds))))**2))))/2)*100/(df[target].max()-df[target].min())),4))\n",
    "    results=pd.DataFrame.from_dict(results) \n",
    "    results.to_csv(handle, index=True)  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6df321",
   "metadata": {},
   "source": [
    "# 4. Main Body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef877d9",
   "metadata": {},
   "source": [
    "## 4.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2514ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gr,gr_expand=load(handel=r\"r1_gr_expand_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aceba7c",
   "metadata": {},
   "source": [
    "## 4.2 Stratify data according to the levels of the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_expand=gr_expand[~gr_expand['Molecule'].isin(['XeCl','AgBi','Hg2','HgCl'])] # the molecules XeCl, AgBi , Hg2 and HgCl has been removed due to uncertainties in their experimental spectroscopic constants values \n",
    "gr_expand['rcat']=gr_expand['Re (\\AA)'] # gr_expand['rcat'] will be used to define strata for the process of stratified sampling\n",
    "gr_expand_unique=np.unique(gr_expand['rcat']) # gr_expand_unique define the unique values of gr_expand['rcat']\n",
    "ind=[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,309] # indicies used to defined strata for the stratified random sampling \n",
    "for i in range(len(ind)-1): \n",
    "    gr_expand['rcat'].where((gr_expand['rcat']>gr_expand_unique[ind[i+1]])|(gr_expand['rcat']<=gr_expand_unique[ind[i]]),gr_expand_unique[ind[i]],inplace=True) # stratification according to the levels of the target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d24dd",
   "metadata": {},
   "source": [
    "## 4.3 Run MC-CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "trval,train,test,mean_std,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds=ml_model(data=gr_expand,strata=gr_expand['rcat'],test_size=31,features=['p1','p2','g1_lan_act','g2_lan_act'],prior_features=['p1','p2','g1_lan_act','g2_lan_act'],target='Re (\\AA)',logtarget='Re (\\AA)',nu=1/2,normalize_y=False,n_splits=1000) #MC-CV gpr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffa3f0",
   "metadata": {},
   "source": [
    "## 4.4 Plot and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train_preds,re_train_std,re_test_preds,re_test_std,out,fig,ax=plot_results(gr_expand,'True $R_e(\\AA)$','Predicted $R_e(\\AA)$','Re (\\AA)',r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds); # plotting scatter plots \n",
    "pyplot.savefig('r1_scatter.svg')\n",
    "for i in range(len(re_test_preds)):\n",
    "    if abs(gr_expand['Re (\\AA)'].tolist()[i]-re_test_preds[i])<0.1:\n",
    "        continue\n",
    "    ax.annotate(gr_expand['Molecule'].tolist()[i], (gr_expand['Re (\\AA)'].tolist()[i], re_test_preds[i])) # annotating molecules with 0.1 angstrom absolute error \n",
    "pyplot.savefig('r1_scatter_ann.svg') # saving the annotated scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a36a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results('r1 model',gr_expand,'Re (\\AA)',re_test_preds,314,MAE,RMSE,R,r\"stat_summ.csv\") # saving results and scores\n",
    "gr_expand['re_test_preds']=re_test_preds # saving the average testing predictions for each molecule over the MC-CV splits\n",
    "gr_expand['re_test_std']=re_test_std # saving the average testing standard deviations for each molecule over the MC-CV splits\n",
    "gr_expand['re_train_preds']=re_train_preds # saving the average training predictions for each molecule over the MC-CV splits\n",
    "gr_expand['re_train_std']=re_train_std # saving the average training standard deviations for each molecule over the MC-CV splits\n",
    "gr_expand.to_csv('r1_gr_expand_pred.csv')\n",
    "split_stat = pd.DataFrame(list(zip(Train_MAE,Train_RMSE,Train_R,MAE,RMSE,R)),columns =['Train_MAE','Train_RMSE','Train_R','MAE','RMSE','R']) # saving final scores for each split\n",
    "split_stat.to_csv('r1_split_stat.csv') # saving final scores for each split in a CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
