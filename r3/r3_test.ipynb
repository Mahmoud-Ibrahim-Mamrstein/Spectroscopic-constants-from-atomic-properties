{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744354f6",
   "metadata": {},
   "source": [
    "# Testing model r3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a17d8",
   "metadata": {},
   "source": [
    "# 1. Import libraries and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe5e53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "import math\n",
    "from math import sqrt\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Product, Matern, WhiteKernel, RBF, DotProduct, ExpSineSquared\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24caa3",
   "metadata": {},
   "source": [
    "# 2. Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba4c54",
   "metadata": {},
   "source": [
    "## Increasing the maximum number of iterations for the optmizer of the Gaussian processes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c4eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPR(GaussianProcessRegressor):\n",
    "    def __init__(self, *args, max_iter=1000000, gtol=1e-6, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._max_iter = max_iter\n",
    "        self._gtol = gtol\n",
    "\n",
    "    def _constrained_optimization(self, obj_func, initial_theta, bounds):\n",
    "        if self.optimizer == \"fmin_l_bfgs_b\":\n",
    "            opt_res = scipy.optimize.minimize(obj_func, initial_theta, method=\"L-BFGS-B\", jac=True, bounds=bounds,tol=self._gtol, options={'maxiter':self._max_iter, 'disp':True})\n",
    "            #_check_optimize_result(\"lbfgs\", opt_res)\n",
    "            theta_opt, func_min = opt_res.x, opt_res.fun\n",
    "        elif callable(self.optimizer):\n",
    "            theta_opt, func_min = self.optimizer(obj_func, initial_theta, bounds=bounds)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown optimizer %s.\" % self.optimizer)\n",
    "            \n",
    "        return theta_opt, func_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564595ea",
   "metadata": {},
   "source": [
    "# 3. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae56f6",
   "metadata": {},
   "source": [
    "## 3.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6149c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(handel,old_handel): #Load is a function that takes the handles of the two CSV files containing the full data set (including old and new data) and the data set containing the data from Liu et al. 2021 and returns multiple pandas data frames of the data as defined below\n",
    "    dfe=pd.read_csv(handel,index_col=None)\n",
    "    df1=pd.read_csv(r\"peridic.csv\",index_col=None) #Includes information from the periodic table for each element\n",
    "    dfe= dfe.loc[:, ~dfe.columns.str.contains('^Unnamed')]\n",
    "    nul=[np.NaN]*len(dfe.Molecule)\n",
    "    for char in ['e1','e2']: #creating two columns that take in the number of electrons of the elements compromising the diatomic molecules\n",
    "        dfe[char]=nul\n",
    "    for char in df1.Symbol:\n",
    "        ind1=dfe.loc[dfe['Molecule'].str.contains(r'^'+char+r'\\D')].index.values\n",
    "        ind2=dfe.loc[dfe['Molecule'].str.contains(char+r'$')].index.values\n",
    "        ind3=dfe.loc[dfe['Molecule'].str.contains(r'^'+char+r'2')].index.values\n",
    "        dfe.loc[ind1,'e1']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind2,'e2']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind3,'e1']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "        dfe.loc[ind3,'e2']=df1[df1.Symbol==char].NumberofElectrons.values[0]\n",
    "    g=dfe\n",
    "    g['n1']=g.A1-g.e1 #number of neutrons of element 1 in a diatomic molecule\n",
    "    g['n2']=g.A2-g.e2 #number of neutrons of element 2 in a diatomic molecule\n",
    "    g.loc[g.atom2=='H','p2']=[1]*len(g.loc[g.atom2=='H']['p2'])\n",
    "    g.loc[g.atom1=='H','p1']=[1]*len(g.loc[g.atom1=='H']['p1'])\n",
    "    g.loc[g.atom2=='H','g2_lan_act']=[1]*len(g.loc[g.atom2=='H']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='H','g1_lan_act']=[1]*len(g.loc[g.atom1=='H']['g1_lan_act'])\n",
    "    #the 'lan_act' extension to 'g1' and 'g2' indicates that Lanthanides and Actinides are included and both are indicated by group number 3.\n",
    "\n",
    "    \n",
    "    g.loc[g.atom2=='D','p2']=[1]*len(g.loc[g.atom2=='D']['p2'])\n",
    "    g.loc[g.atom1=='D','p1']=[1]*len(g.loc[g.atom1=='D']['p1'])\n",
    "    g.loc[g.atom2=='T','p2']=[1]*len(g.loc[g.atom2=='T']['p2'])\n",
    "    g.loc[g.atom1=='T','p1']=[1]*len(g.loc[g.atom1=='T']['p1'])\n",
    "    g.loc[g.atom2=='D','g2']=[1]*len(g.loc[g.atom2=='D']['g2'])\n",
    "    g.loc[g.atom1=='D','g1']=[1]*len(g.loc[g.atom1=='D']['g1'])\n",
    "    g.loc[g.atom2=='T','g2']=[1]*len(g.loc[g.atom2=='T']['g2'])\n",
    "    g.loc[g.atom1=='T','g1']=[1]*len(g.loc[g.atom1=='T']['g1'])\n",
    "    g.loc[g.atom2=='D','g2_lan_act']=[1]*len(g.loc[g.atom2=='D']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='D','g1_lan_act']=[1]*len(g.loc[g.atom1=='D']['g1_lan_act'])\n",
    "    g.loc[g.atom2=='T','g2_lan_act']=[1]*len(g.loc[g.atom2=='T']['g2_lan_act'])\n",
    "    g.loc[g.atom1=='T','g1_lan_act']=[1]*len(g.loc[g.atom1=='T']['g1_lan_act'])\n",
    "    g.loc[g.atom2=='D','g2_lan_act_iso']=[0]*len(g.loc[g.atom2=='D']['g2_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements  \n",
    "    g.loc[g.atom1=='D','g1_lan_act_iso']=[0]*len(g.loc[g.atom1=='D']['g1_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements \n",
    "    g.loc[g.atom2=='T','g2_lan_act_iso']=[-1]*len(g.loc[g.atom2=='T']['g2_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements \n",
    "    g.loc[g.atom1=='T','g1_lan_act_iso']=[-1]*len(g.loc[g.atom1=='T']['g1_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements \n",
    "    g.loc[g.atom2=='H','g2_lan_act_iso']=[1]*len(g.loc[g.atom2=='H']['g2_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements \n",
    "    g.loc[g.atom1=='H','g1_lan_act_iso']=[1]*len(g.loc[g.atom1=='H']['g1_lan_act_iso']) #including the isotopic character in some atoms through the groups of the perspective elements\n",
    "    #creating different variations of features and targets \n",
    "    g['sum_p']=g['p1']+g['p2']\n",
    "    g['sum_g']=g.g1_lan_act+g.g2_lan_act\n",
    "    g['diff_p']=abs(g['p1']-g['p2'])\n",
    "    g['diff_g']=abs(g['g1_lan_act']-g['g2_lan_act'])\n",
    "    g['product_p']=g['p1']*g['p2']\n",
    "    g['product_g']=g['g1_lan_act']*g['g1_lan_act']\n",
    "    g['Reduced_g']=(g.g1_lan_act*g.g2_lan_act)/(g.g1_lan_act+g.g2_lan_act)\n",
    "    g['Reduced_p']=(g.p1*g.p2)/(g.p1+g.p2)\n",
    "    g['g_average']=(g.g1+g.g2)/2\n",
    "    g['g_average_lan_act']=(g.g1_lan_act+g.g2_lan_act)/2\n",
    "    g['g_average_lan_act_iso']=(g.g1_lan_act_iso+g.g2_lan_act_iso)/2\n",
    "    g['Re (\\AA)^-1']=1/((g['Re (\\AA)']))\n",
    "    g['Re (au)']=((g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['Re (au)^-1']=1/((g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['Re (au)^2']=((g['Re (\\AA)'])*1.8897259885789)**2\n",
    "    g['Re (au)^-2']=1/g['Re (au)^2']\n",
    "    g['4*(np.pi**2)*Re (au)']=(4*(np.pi**2)*(g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['4*(np.pi**2)*Re (au)^-1']=1/(4*(np.pi**2)*(g['Re (\\AA)'])*1.8897259885789)\n",
    "    g['omega_e (au)^-2']=1/((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['4*(np.pi**2)*omega_e (au)^-2']=1/((2*(np.pi)*g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['omega_e (au)']=(g['omega_e (cm^{-1})']*(0.0000046))\n",
    "    g['omega_e (au)^2']=((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['4*(np.pi**2)*omega_e (au)^2']=4*(np.pi**2)*((g['omega_e (cm^{-1})']*(0.0000046))**2)\n",
    "    g['K']=(4*(np.pi**2)*((g['omega_e (cm^{-1})'])**2)*g['Reduced mass'])\n",
    "    g['sqrt(K)']=np.sqrt(4*(np.pi**2)*((g['omega_e (cm^{-1})'])**2)*g['Reduced mass'])\n",
    "    g['4*(np.pi**2)*omega_e (au)']=4*(np.pi**2)*((g['omega_e (cm^{-1})']*(0.0000046)))\n",
    "    g['4*(np.pi**2)*Re (au)*omega_e (au)^2']=g['4*(np.pi**2)*Re (au)']*((g['omega_e (cm^{-1})']*0.0000046)**2)\n",
    "    g['ve1']=g['g1_lan_act']\n",
    "    g['ve2']=g['g2_lan_act']\n",
    "    g['log(D_e)/(R_e^3*Z_1*Z_2)']=np.log((g[\"D0 (eV)\"]*0.037)/((g[\"Re (au)\"]**3)*g.e1*g.e2))\n",
    "    g.loc[g.g2_lan_act==18,'ve2']=[0]*len(g.loc[g.g2_lan_act==18]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==18,'ve1']=[0]*len(g.loc[g.g1_lan_act==18]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==17,'ve2']=[7]*len(g.loc[g.g2_lan_act==17]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==17,'ve1']=[7]*len(g.loc[g.g1_lan_act==17]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==16,'ve2']=[6]*len(g.loc[g.g2_lan_act==16]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==16,'ve1']=[6]*len(g.loc[g.g1_lan_act==16]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==15,'ve2']=[5]*len(g.loc[g.g2_lan_act==15]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==15,'ve1']=[5]*len(g.loc[g.g1_lan_act==15]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==14,'ve2']=[4]*len(g.loc[g.g2_lan_act==14]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==14,'ve1']=[4]*len(g.loc[g.g1_lan_act==14]['g1_lan_act'])\n",
    "    g.loc[g.g2_lan_act==13,'ve2']=[3]*len(g.loc[g.g2_lan_act==13]['g2_lan_act'])\n",
    "    g.loc[g.g1_lan_act==13,'ve1']=[3]*len(g.loc[g.g1_lan_act==13]['g1_lan_act'])\n",
    "    g.loc[g.type2=='Transition Metal','ve2']=[2]*len(g.loc[g.type2=='Transition Metal']['g2_lan_act'])\n",
    "    g.loc[g.type1=='Transition Metal','ve1']=[2]*len(g.loc[g.type1=='Transition Metal']['g1_lan_act'])\n",
    "    #redfinining valence electrons\n",
    "    g= g.loc[:, ~g.columns.str.contains('^Unnamed')]\n",
    "    g_dict=g.to_dict(orient='list')\n",
    "    old=pd.read_csv(old_handel) #loading data from the Liu et al. 2021 paper\n",
    "    old=old[old[\"Te (cm^{-1})\"]==0]\n",
    "    old.drop_duplicates(inplace=True)\n",
    "    #creating different pandas dataframes for different purposes\n",
    "    gr=g[g[\"Re (\\AA)\"].isna()==False] #gr only contains molecules that have R_e available \n",
    "    gw=gr[gr[\"omega_e (cm^{-1})\"].isna()==False] #gw only contains molecules that have R_e and omega_e available\n",
    "    g_new=g.loc[g['Molecule'].isin(old.Molecule)==False] #g_new contains only new data\n",
    "    g_old=g.loc[g['Molecule'].isin(old.Molecule)] #g_new contains only old data from liu et al., 2021\n",
    "    gr_old=g_old[g_old[\"Re (\\AA)\"].isna()==False] #gr_old only contains molecules that have R_e available from liu et al., 2021\n",
    "    gw_old=gr_old[gr_old[\"omega_e (cm^{-1})\"].isna()==False] #gw_old only contains molecules that have R_e and omega_e available from liu et al., 2021\n",
    "    gr_new=g_new[g_new[\"Re (\\AA)\"].isna()==False] #gr_new only contains new molecules that have R_e available\n",
    "    gw_new=gr_new[gr_new[\"omega_e (cm^{-1})\"].isna()==False] #gw_new only contains new molecules that have R_e and omega_e available\n",
    "    \n",
    "    # permuting the properties of atoms 1 and 2 in the diatomic molecules as described in Liu et al., 2021 and in the manuscript, to create expanded data frames containing both A-B and B-A molecules\n",
    "    reverse=['A1','A2','g1','g2','p1','p2','g1iso','g2iso','g1_lan_act','g2_lan_act','g1_lan_act_iso','g2_lan_act_iso','atom1','atom2','type1','type2','e1','e2','ve1','ve2']\n",
    "    for key,value in g_dict.items():\n",
    "        if key in reverse:\n",
    "            continue \n",
    "        else:\n",
    "            g_dict[key]=value+value\n",
    "    s=0        \n",
    "    for i in range(len(reverse)):\n",
    "            if s==len(reverse):\n",
    "                break\n",
    "            A=g_dict[reverse[s]]+g_dict[reverse[s+1]]\n",
    "            B=g_dict[reverse[s+1]]+g_dict[reverse[s]]\n",
    "            g_dict[reverse[s]]=A\n",
    "            g_dict[reverse[s+1]]=B\n",
    "            s=s+2\n",
    "    #the extension '-expand' indicates the inclusion of both A-B and B-A variations of the diatomic molecule in the datafram\n",
    "    g_expand=pd.DataFrame.from_dict(g_dict, orient='columns')\n",
    "    g_expand.drop_duplicates(subset=['A1','A2','g1','g2','p1','p2','g1iso','g2iso','g1_lan_act','g2_lan_act','g1_lan_act_iso','g2_lan_act_iso','atom1','atom2','type1','type2','ve1','ve2'], keep='first', inplace=True, ignore_index=False)\n",
    "    gr_expand=g_expand[g_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_expand=gr_expand[gr_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "\n",
    "    g_new_expand=g_expand.loc[g_expand['Molecule'].isin(old.Molecule)==False]\n",
    "    g_old_expand=g_expand.loc[g_expand['Molecule'].isin(old.Molecule)]\n",
    "    gr_old_expand=g_old_expand[g_old_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_old_expand=gr_old_expand[gr_old_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    gr_new_expand=g_new_expand[g_new_expand[\"Re (\\AA)\"].isna()==False]\n",
    "    gw_new_expand=gr_new_expand[gr_new_expand[\"omega_e (cm^{-1})\"].isna()==False]\n",
    "    return g,gr,gw, g_old, g_new, gr_old, gw_old, gr_new, gw_new, g_expand, gr_expand, gw_expand, g_old_expand, g_new_expand, gr_old_expand, gw_old_expand, gr_new_expand, gw_new_expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8ab65",
   "metadata": {},
   "source": [
    "## 3.3 Function that perfroms the loo splits, train the GPR and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80ced0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model(data,features,prior_features,logtarget,target,nu,normalize_y): #function used for implementing the leave one out GPR model for testing\n",
    "    r_y_train_preds={} # Initiate a dictionary to store training predictions\n",
    "    r_y_test_preds={} # Initiate a dictionary to store testing predictions\n",
    "    r_train_stds={} # Initiate a dictionary to store training standard deviations\n",
    "    r_test_stds={} # Initiate a dictionary to store testing standard deviations\n",
    "    trval={} #intiate a dictionary to store optimized kernels and scores\n",
    "    start_time = time.time() #Timing the algorithm\n",
    "    RMSE=[] # Intiate a list to store the test RMSE of all loo steps\n",
    "    RMSLE=[] # Intiate a list to store the test RMSLE of all loo steps\n",
    "    MAE=[] # Intiate a list to store the test MAE of all loo steps\n",
    "    R=[] # Intiate a list to store the test normalized RMSE % of all loo steps\n",
    "    Train_RMSE=[] # Intiate a list to store the train RMSE of all loo steps\n",
    "    Train_RMSLE=[] # Intiate a list to store the train RMSLE of all loo steps\n",
    "    Train_MAE=[] # Intiate a list to store the train MAE of all loo steps\n",
    "    Train_R=[] # Intiate a list to store the train normalized RMSE % of all loo steps\n",
    "    mean_std=[] # Intiate a list to store the mean test std of all loo steps\n",
    "    train=[]\n",
    "    test=[] \n",
    "\n",
    "    loo = LeaveOneOut() # Using the leave one out object from sklearn for final testing\n",
    "    \n",
    "    s=0\n",
    "    \n",
    "    for train_index, test_index in loo.split(data): # leave one out is used for testing. That is the whole data set is used in the kernel to make one prediction\n",
    "        re_train_set1 = data.iloc[train_index] # The dataframe's training rows returend from loo.split(data)\n",
    "        re_train_set1['ind']=train_index #The dataframe's training rows' indicies returend from loo.split(data)\n",
    "        re_test_set1 = data.iloc[test_index] # The dataframe's testing rows returend from loo.split(data)\n",
    "        re_test_set1['ind']=test_index #The dataframe's testing rows' indicies returend from loo.split(data)\n",
    "        \n",
    "        re_train_set=re_train_set1[~re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())] #Removing A-B molecules from the training set if their mirror molecules (B-A molecules) are in the testing set\n",
    "        re_test_set=pd.concat([re_test_set1,re_train_set1[re_train_set1['Molecule'].isin(re_test_set1['Molecule'].tolist())]]) #Placing miror molecules from the training set in the testing set so that A-B and B-A moleculesa re both in the testing set\n",
    "        \n",
    "        for i in re_train_set['Molecule'].isin([re_test_set['Molecule']]):\n",
    "            if i ==True:\n",
    "                print(i)\n",
    "                print('warning: A molecule in the test set is aslo in the training set')\n",
    "        #print('size of training set after removing mirror molecules',len(re_train_set))\n",
    "        #print('size of test set after adding mirror molecules',len(re_test_set))\n",
    "        train.append(re_train_set['Molecule'])\n",
    "        if (re_test_set['Molecule'].tolist()) in test:\n",
    "            #continue\n",
    "            break\n",
    "\n",
    "        test.append(re_test_set['Molecule'].tolist())\n",
    "        #print(test)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        trval[str(s)]={} # intiate a dictionary that stores the three parameters values after optimization for each split s\n",
    "        trval[str(s)]['$\\sigma^2$']=1 # intiate the value of the multiplicative constant of the kernel\n",
    "        trval[str(s)]['length scale']=1 # intiate the value of the length scale\n",
    "        trval[str(s)]['noise level']=1 # intiate the value of the noise level in the additive white kernel\n",
    "        \n",
    "        if re_test_set['Molecule'].tolist()[0] not in ['MoC','NbC','NiC','NiO','NiS','PbI','PdC','RuC','SnI','UO','WC','YC','ZnBr','ZnCl','WO','ZnI','ZnF','HCl','DCl']:\n",
    "            continue # only make prediction is the molecule is in the following list ['MoC','NbC','NiC','NiO','NiS','PbI','PdC','RuC','SnI','UO','WC','YC','ZnBr','ZnCl','WO','ZnI','ZnF','HCl','DCl']\n",
    "            \n",
    "        reg = LinearRegression().fit(re_train_set[prior_features], re_train_set[logtarget]) #Liner regression model to fix the constatns coefficients of the prirori mean function in each loo step\n",
    "        \n",
    "        re_train_set['prior_mean']=reg.predict(re_train_set[prior_features])\n",
    "        re_test_set['prior_mean']=reg.predict(re_test_set[prior_features])\n",
    "        \n",
    "        prior_mean='prior_mean'\n",
    "        signal_variance=(re_train_set[logtarget].var()) #Intiate constant cooefcient of the Matern kernel function\n",
    "        length_scale=(re_train_set[features].std()).mean() #Intiate length scale of the Matern kernel function\n",
    "        gpr = MyGPR(kernel=ConstantKernel(constant_value=signal_variance)*Matern(length_scale=length_scale, nu=nu)+WhiteKernel(noise_level=re_train_set[target].std()/np.sqrt(2),noise_level_bounds=(10**-15,1)),n_restarts_optimizer=20,normalize_y=normalize_y,random_state=42) #Using MYGPR class with the matern Kernel with multiplicative constant and additive white noise kernel as defined in the manuscript\n",
    "        gpr.fit(re_train_set[features], re_train_set[logtarget]-re_train_set[prior_mean]) # Optmizing the kernel parameters using the fitting data (the target is offset by the prior mean)\n",
    "\n",
    "\n",
    "        r_y_train_pred_log,r_std_train=gpr.predict(re_train_set[features], return_std=True)  #train predictions, and train standard deviations\n",
    "        r_y_test_pred_log,r_std_test=gpr.predict(re_test_set[features], return_std=True) #test predictions, and train standard deviations\n",
    "        \n",
    "        r_y_train_pred_log=r_y_train_pred_log+np.array(re_train_set[prior_mean]) #adding the prior mean back\n",
    "        r_y_test_pred_log=r_y_test_pred_log+np.array(re_test_set[prior_mean]) #adding the prior mean back\n",
    "        \n",
    "        r_y_train_pred=r_y_train_pred_log #log transformation was not used in predicting R_e\n",
    "        r_y_test_pred=r_y_test_pred_log #log transformation was not used in predicting R_e\n",
    "\n",
    "        \n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('negative result') #indicates negative results if any \n",
    "        r_y_test_pred=(np.array(r_y_test_pred))\n",
    "        for m in range(len(r_y_test_pred)):\n",
    "            if r_y_test_pred[m]<0:\n",
    "                print('negative result') #indicates negative results if any \n",
    "\n",
    "        \n",
    "        for  mol in  re_test_set['Molecule'].tolist():\n",
    "            test.append(mol)\n",
    "        mean_std.append(np.array(r_std_test).mean())  #calculating mean standard deviations\n",
    "\n",
    "        trval[str(s)]['mean_std']=mean_std[-1]\n",
    "\n",
    "        RMSE.append(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred))) #calculating test RMSE of the split and appending it to the Train_RMSE list\n",
    "\n",
    "        trval[str(s)]['RMSE']=RMSE[-1] #RMSE of split s\n",
    "        \n",
    "        Train_RMSE.append(np.sqrt(mean_squared_error(re_train_set[target],r_y_train_pred)))  #calculating train RMSE of the split and appending it to the Train_RMSE list\n",
    "\n",
    "        trval[str(s)]['Train_RMSE']=Train_RMSE[-1] #Train RMSE of split s\n",
    "        \n",
    "        RMSLE.append(np.sqrt(mean_squared_error(re_test_set[logtarget],r_y_test_pred_log))) #calculating test RMSLE of the split and appending it to the test RMSLE list\n",
    "\n",
    "        trval[str(s)]['RMSLE']=RMSLE[-1] #Test RMSLE of split s\n",
    "        \n",
    "                \n",
    "        Train_RMSLE.append(np.sqrt(mean_squared_error(re_train_set[logtarget],r_y_train_pred_log))) #calculating train RMSLE of the split and appending it to the Train_RMSLE list \n",
    "\n",
    "        trval[str(s)]['Train_RMSLE']=Train_RMSLE[-1] #Train RMSLE of split s\n",
    "\n",
    "        MAE.append(sum(abs(re_test_set[target]-(r_y_test_pred)))/len(re_test_set[target])) #calculating test MAE of the split and appending it to the test MAE list\n",
    "\n",
    "        trval[str(s)]['MAE']=MAE[-1] #Train MAE of split s\n",
    "        \n",
    "        Train_MAE.append(sum(abs(re_train_set[target]-(r_y_train_pred)))/len(re_train_set[target])) #calculating train MAE of the split and appending it to the Train_MAE list\n",
    "\n",
    "        trval[str(s)]['Train_MAE']=Train_MAE[-1] #Train MAE of split s\n",
    "\n",
    "        R.append(100*(np.sqrt(mean_squared_error(re_test_set[target],r_y_test_pred)))/((data[target]).max()-(data[target]).min())) #calculating test R of the split and appending it to the test R list \n",
    "\n",
    "        trval[str(s)]['R']=R[-1] #Test R of split s\n",
    "        \n",
    "    \n",
    "        s=s+1 # incrementing the loo split counter\n",
    "        \n",
    "\n",
    "        for i in range(len(re_train_set.ind)):\n",
    "            if re_train_set.ind.tolist()[i] not in r_y_train_preds:   \n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]]=[r_y_train_pred[i]] #adding loo train prediction list of a molecule of index 'i' which is not yet in re_train_set dictionary\n",
    "                r_train_stds[re_train_set.ind.tolist()[i]]=[r_std_train[i]] #adding loo train GPR standard deviation list of a molecule of index 'i' not yet in r_train_stds dictionary\n",
    "\n",
    "                #print(\"Molecule: \",re_train_set.loc[train_index[i],'Molecule'],\"true: \",gr.loc[train_index[i],'Re (\\AA)'],\"pred: \",r_y_train_pred[i],\"standard deviation: \",r_std_train[i])\n",
    "\n",
    "            else:\n",
    "                r_y_train_preds[re_train_set.ind.tolist()[i]].append(r_y_train_pred[i])  #apeending new loo train prediction to an existing list of predictions of a molecule indexed i in the r_y_train_preds dictionary\n",
    "                r_train_stds[re_train_set.ind.tolist()[i]].append(r_std_train[i]) #apeending new loo train standard deviation to an existing list of predictions of a molecule indexed i in the r_train_stds dictionary\n",
    "                \n",
    "        for i in range(len(re_test_set.ind)):\n",
    "            if re_test_set.ind.tolist()[i] not in r_y_test_preds:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]]=[r_y_test_pred[i]] #adding loo test prediction list of a molecule of index 'i' which is not yet in re_test_set dictionary\n",
    "                r_test_stds[re_test_set.ind.tolist()[i]]=[r_std_test[i]] #adding loo test GPR standard deviation list of a molecule of index 'i' not yet in r_test_stds dictionary\n",
    "            else:\n",
    "                r_y_test_preds[re_test_set.ind.tolist()[i]].append(r_y_test_pred[i]) #apeending new loo test prediction to an existing list of predictions of a molecule indexed 'i' in the r_y_test_preds dictionary\n",
    "                r_test_stds[re_test_set.ind.tolist()[i]].append(r_std_test[i]) #apeending new loo test standard deviation to an existing list of predictions of a molecule indexed 'i' in the r_test_stds dictionary\n",
    "    end_time = time.time()\n",
    "    retime=end_time-start_time\n",
    "    retime # timing the validation stage\n",
    "    return trval,train,test,mean_std,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750c788",
   "metadata": {},
   "source": [
    "# 4. Main Body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc8a60",
   "metadata": {},
   "source": [
    "## 4.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01adb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "g,gr,gw, g_old, g_new, gr_old, gw_old, gr_new, gw_new, g_expand, gr_expand, gw_expand, g_old_expand, g_new_expand, gr_old_expand, gw_old_expand, gr_new_expand, gw_new_expand=load(handel=r\"r3_gw_expand_test.csv\",old_handel=r\"list of molecules used in Xiangue and Jesus paper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee30f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_expand=gw_expand[~gw_expand['Molecule'].isin(['AgBi','Hg2','XeCl','HgCl','HgBr',\"HgI\"])] # Removing moleules with uncertain experimental values of their spectroscopic constnants\n",
    "gw_expand['mu^(1/2)']=(np.sqrt(gw_expand['Reduced mass'])) # The square root of the reduced mass is used as a feature\n",
    "gw_expand['ln(mu^(1/2))']=np.log(np.sqrt(gw_expand['Reduced mass'])) # The logaritm of the square root of the reduced mass is used as a feature\n",
    "gw_expand['ln(w)']=np.log(gw_expand['omega_e (cm^{-1})']) #The natural logaritm of the square root of $\\omega_e$ will be used as a variable in the prior mean function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fb41a",
   "metadata": {},
   "source": [
    "## 4.2 Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trval,train,test,mean_std,Train_MAE,Train_RMSE,Train_R,Train_RMSLE,MAE,RMSE,R,RMSLE,r_y_train_preds,r_train_stds,r_y_test_preds,r_test_stds=ml_model(data=gw_expand,features=['p1','p2','g1_lan_act','g2_lan_act','mu^(1/2)'],prior_features=['ln(w)','ln(mu^(1/2))','p1','p2','g1_lan_act','g2_lan_act'],target='Re (\\AA)',logtarget='Re (\\AA)',nu=3/2,normalize_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a220d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_molecules=gw_expand[gw_expand['Molecule'].isin(['MoC','NbC','NiC','NiO','NiS','PbI','PdC','RuC','SnI','UO','WC','YC','ZnBr','ZnCl','WO','ZnI','ZnF','HCl','DCl'])].drop_duplicates(subset='Molecule')['Molecule'].tolist()\n",
    "true_values=gw_expand[gw_expand['Molecule'].isin(['MoC','NbC','NiC','NiO','NiS','PbI','PdC','RuC','SnI','UO','WC','YC','ZnBr','ZnCl','WO','ZnI','ZnF','HCl','DCl'])].drop_duplicates(subset='Molecule')['Re (\\AA)'].tolist()\n",
    "re_test_preds=[]\n",
    "re_test_std=[]\n",
    "out=[]\n",
    "for index in r_y_test_preds:\n",
    "        if index >= 328:\n",
    "                continue\n",
    "        re_test_preds.append(((r_y_test_preds[index][0])))\n",
    "        re_test_std.append(((r_test_stds[index][0])))\n",
    "testing_results = pd.DataFrame(list(zip(test_molecules, true_values,re_test_preds,re_test_std)), columns =['Molecule', 'true $R_e (\\AA)$','Predicted $R_e (\\AA)$','error bars'])\n",
    "testing_results.to_csv(r'r3_testing_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
